# FontDetector

FontDetector — это прототип системы определения шрифтов по изображению текста. Репозиторий содержит обученную сверточную нейросеть, FastAPI‑приложение и минимальный фронтенд для демонстрации работы модели.

## Краткое описание приложения
1. **Загрузка изображения.** Пользователь выбирает или вставляет картинку с текстом в веб‑интерфейсе (`fast_api/index.html`, `fast_api/static/main.js`).
2. **Отправка на сервер.** JavaScript формирует `FormData` с файлом и отправляет его POST‑запросом на эндпоинт `/predict` FastAPI‑приложения.
3. **Обработка изображения.** В `fast_api/app.py`:
   - изображение переводится в градации серого, бинаризуется и при необходимости инвертируется;
   - картинка масштабируется до 100×300 и преобразуется в тензор Torch;
   - тензор подается в сверточную сеть `BaseNet`, веса которой загружаются из `model.pth`, чтобы получить эмбеддинг фиксированной длины;
   - эмбеддинг сравнивается с предвычисленными средними эмбеддингами (`test_average_embeddings.pkl`) по евклидову расстоянию и выбираются 3 ближайших шрифта;
   - для каждого кандидата генерируется пример текста «АБВГД абвгд 12345» с помощью исходного шрифта (`downloaded_fonts/*.otf`).
4. **Возврат результата.** Сервер отправляет JSON со списком картинок‑примеров и подписей, браузер показывает их пользователю.

## Структура репозитория
| Путь | Назначение |
| --- | --- |
| `fast_api/app.py` | Основной код FastAPI‑приложения, модель и инференс. |
| `fast_api/index.html` | Минимальная HTML‑страница с формой загрузки. |
| `fast_api/static/main.js` | Логика UI: предпросмотр, отправка запроса, отображение ответов. |
| `model.pth` | Веса сверточной сети `BaseNet`. |
| `test_average_embeddings.pkl` | Словарь `{название шрифта: средний эмбеддинг}`. |
| `font_detector_ipynb_.py` | Выгруженный из Jupyter ноутбука скрипт с экспериментальным кодом. |
| `utils.py` | Утилиты подготовки данных. |
| `requirements.txt` | Перечень зависимостей для запуска. |

## Подробное описание ключевых файлов

### `font_detector_ipynb_.py` — подготовка данных и обучение модели
Скрипт представляет собой экспорт ноутбука Google Colab, в котором шаг за шагом построен весь процесс подготовки прототипа модели:

1. **Сбор шрифтов.** Через Google Fonts API (`get_font_list`, `download_font_file`) скачиваются популярные гарнитуры с поддержкой кириллицы. Файлы складываются в каталог `downloaded_fonts`, а затем архивируются для удобной выгрузки.
2. **Генерация датасета.** В блоке «ГЕНЕРАЦИЯ КАРТИНОК» создаются синтетические изображения (`generated_images`): для каждого шрифта рендерится набор случайных фраз (цифры + кириллица) на фоне случайного цвета, добавляется Gaussian blur/шум. Функции `random_string`, `add_gaussian_noise`, `random_contrast_color` управляют вариативностью.
3. **Загрузка и препроцессинг.** Полученные PNG разбиваются на train/test, каждая картинка приводится к размеру 100×300, бинаризуется и превращается в тензор через `parse_function` (OpenCV + torchvision `transforms`).
4. **Формирование выборок для triplet loss.** Класс `TripletDataset` собирает триплеты (anchor/positive/negative) внутри `DataLoader`, чтобы оптимизировать модель на разделение шрифтов в пространстве эмбеддингов.
5. **Модель и обучение.** Определена сверточная сеть `BaseNet` (три блока Conv-ReLU + MaxPool, затем полносвязный классификатор на 256‑мерный эмбеддинг) и `TripletLoss`. В цикле на 12 эпох оптимизатор RMSprop минимизирует loss по мини‑батчам, после каждой эпохи считается top‑1/top‑5 accuracy с помощью функций `predict_font` и `predict_top_fonts`.
6. **Сохранение артефактов.** Весы модели (`model.pth`) и усредненные эмбеддинги шрифтов (`test_average_embeddings.pkl`) сохраняются и скачиваются — эти файлы затем используются приложением для инференса.

### `fast_api/app.py` — запуск сервиса и использование модели
Файл отвечает за продакшен‑инференс и взаимодействие с клиентом:

1. **Инициализация приложения.** Создается `FastAPI`‑приложение, монтируется статика (`/static`). При GET `/` возвращается `index.html` для фронтенда.
2. **Загрузка модели.** Класс `BaseNet` повторяет архитектуру обучения, веса читаются из `../model.pth`, а словарь средних эмбеддингов — из `../test_average_embeddings.pkl`. Модель переводится в режим `eval()`.
3. **Предобработка входа.** Эндпоинт POST `/predict/` принимает изображение, переводит его в `RGB` (Pillow), далее `predict_font_from_image` выполняет OpenCV‑обработку (grayscale, Otsu threshold, возможная инверсия, resize 100×300, `ToTensor`). Полученный тензор подается в сеть.
4. **Сравнение эмбеддингов.** Функция `predict_top_fonts` считает евклидовы расстояния до всех средних эмбеддингов и возвращает `top_n` шрифтов; для каждого кандидата `generate_font_image` рендерит пример текста «АБВГД абвгд 12345» с соответствующим `.otf` файлом.
5. **Формирование ответа.** Сгенерированные изображения сериализуются в Base64 и отправляются в JSON (`{"font_data": [...]}`), чтобы фронтенд сразу показал название и пример шрифта.

### `utils.py` — вспомогательные функции для инференса
Модуль дублирует ключевую математику инференса для переиспользования вне FastAPI:

- `euclidean_distance` — расчёт L2‑нормы между эмбеддингами.
- `predict_font` — поиск ближайшего шрифта по минимальной дистанции (top‑1 сценарий).
- `predict_top_fonts` — сортировка всех шрифтов по расстоянию и возврат списка из `top_n` названий. Эти функции можно импортировать в скрипты/ноутбуки, чтобы тестировать модель без запуска веб‑сервера.

## Быстрый старт
1. Создайте и активируйте виртуальное окружение.
2. Установите зависимости:
   ```bash
   pip install -r requirements.txt
   ```
3. Перейдите в каталог `fast_api` и запустите сервер:
   ```bash
   uvicorn app:app --reload
   ```
4. Откройте в браузере `http://127.0.0.1:8000`, загрузите изображение с текстом и нажмите «Определить шрифт».

## Точки расширения и улучшения
- Добавить обработку ошибок (например, отсутствующие файлы шрифтов, неверный формат изображения) и возвращать понятные сообщения пользователю.
- Расширить UI: прогресс загрузки, предпросмотр результатов в едином блоке, адаптивная верстка.
- Запаковать inference в отдельный модуль/класс и покрыть тестами.
- Добавить Dockerfile и makefile для воспроизводимого деплоя.
- Предусмотреть кэширование сгенерированных изображений шрифтов, чтобы не рендерить их повторно.
- Разделить конфигурацию (пути к весам, числу топ‑результатов) в `.env` или файл настроек.

## Исследовательские сведения
- **Актуальность.** Распознавание шрифтов востребовано в дизайне, брендинге и документообороте: автоматизация поиска похожих гарнитур ускоряет работу дизайнеров и аналитиков.
- **Цель.** Создать прототип, который по изображению текста предлагает несколько наиболее подходящих шрифтов с визуальными примерами.
- **Научная новизна.** Использование эмбеддингов, полученных сверточной сетью, и сравнение их со средними эмбеддингами шрифтов позволяет без полного переобучения модели быстро расширять базу шрифтов и объяснять результат через визуализацию.
- **Объект исследования.** Изображения отрендеренного кириллического текста и их представление в пространстве эмбеддингов.
- **Задача исследования.** Найти способ сопоставлять неизвестный образец текста с уже известными шрифтами, минимизируя вычислительные затраты на инференс и подготовку данных.
- **Методы исследования.** Сверточные нейронные сети для извлечения признаков, евклидова метрика для поиска ближайших соседей, предобработка изображений (бинаризация, нормализация), генерация синтетических примеров текста для визуальной валидации результатов.

## Лицензия
Лицензия в репозитории не указана. Добавьте её при необходимости распространения кода или модели.
