# -*- coding: utf-8 -*-
"""Font Detector__Main_note.ipynb"

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lvIgiNwyhDoMOV943uXJQ2gkU_8iGGZ5

### ЗАГРУЗКА ШРИФТОВ
"""

import requests
import os
import time
from google.colab import files
import shutil

API_KEY = 'AIzaSyAe615_q3lF2v9Ooe5AbtvweX5gxs0968o'
FONT_LIST_URL = 'https://www.googleapis.com/webfonts/v1/webfonts'
DOWNLOAD_DIR = 'downloaded_fonts'
MAX_RETRIES = 100


#Сбор шрифтов
def get_font_list(api_key):
    params = {
        'key': api_key,
        'sort': 'popularity'
    }
    response = requests.get(FONT_LIST_URL, params=params)
    if response.status_code != 200:
        raise ValueError("Error fetching font list from Google Fonts API.")
    return response.json().get('items', [])


#Установка шрифтов
def download_font_file(url, filename):
    retries = 0
    while retries < MAX_RETRIES:
        try:
            response = requests.get(url)
            response.raise_for_status()
            with open(os.path.join(DOWNLOAD_DIR, filename), 'wb') as file:
                file.write(response.content)
            print(f"Successfully downloaded {filename}")
            return
        except requests.RequestException as e:
            print(f"Error downloading {filename}: {e}. Retrying...")
            retries += 1
            time.sleep(2)
    print(f"Failed to download {filename} after {MAX_RETRIES} retries.")

#Созданик каталога шрифтов
if not os.path.exists(DOWNLOAD_DIR):
    os.makedirs(DOWNLOAD_DIR)

#Активация функции сбора
fonts = get_font_list(API_KEY)
i = 0

#Активация функции установки
for font in fonts:
    if "cyrillic-ext" not in font['subsets']:
        continue
    url = font['files'].get('regular', None)
    if url and font['subsets']:
        file_extension = url.split('.')[-1]
        filename = f"{font['family'].replace(' ', '_')}_Regular.{file_extension}"
        download_font_file(url, filename)
    i += 1

shutil.make_archive('./downloaded_fonts', 'zip', './downloaded_fonts')

files.download('./downloaded_fonts.zip')

"""### ГЕНЕРАЦИЯ КАРТИНОК (ДАТАСЕТА)"""

from PIL import Image, ImageDraw, ImageFont, ImageFilter
import os
import random
import string
import numpy as np

font_dir = 'downloaded_fonts'
output_dir = 'generated_images'
phrases_count_per_font = 65


#Генераци набора символов
def random_string(length=30):
    digits = string.digits + ' ' * 10
    cyrillic_letters = 'абвгдеёжзийклмнопрстуфхцчшщъыьэюя' + 'абвгдеёжзийклмнопрстуфхцчшщъыьэюя'.upper()
    all_letters = cyrillic_letters + digits
    return ''.join(random.choice(all_letters) for i in range(length)).strip()


#Добавление шума
def add_gaussian_noise(image, noise_level):
    np_image = np.array(image)
    noise = np.random.normal(0, noise_level, np_image.shape).astype(np.uint8)
    noisy_image = np_image + noise
    noisy_image = np.clip(noisy_image, 0, 255)
    return Image.fromarray(noisy_image, 'RGBA')


#Случайный цвет
def random_contrast_color(base_color):
    r, g, b = base_color
    return 255 - r, 255 - g, 255 - b

#Созданиe каталога сгенерированных изображений шрифтов
if not os.path.exists(output_dir):
    os.makedirs(output_dir)

#Созданиe списка случайных символов
random_phrases = [random_string(random.randint(5, 30)) for i in range(phrases_count_per_font)]

for font_file in os.listdir(font_dir):
    if not font_file.endswith('.ttf') and not font_file.endswith('.otf'):
        continue
    print(font_file)
    try:
        font_path = os.path.join(font_dir, font_file)
        font = ImageFont.truetype(font_path, 60)
    except Exception as e:
        print(f"Could not load font {font_file}: {e}")
        continue
    for phrase in random_phrases:
        phrase = random_string(random.randint(5, 30))
        try:
            bg_color = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))
            text_color = random_contrast_color(bg_color)
            image = Image.new("RGBA", (300, 100), bg_color)
            draw = ImageDraw.Draw(image)
            text_bbox = draw.textbbox(text=phrase, font=font, xy=(0, 0))
            text_width = text_bbox[2] - text_bbox[0]
            text_height = text_bbox[3] - text_bbox[1]

            while text_width > 290:
                phrase = phrase[:-1]
                text_bbox = draw.textbbox(text=phrase, font=font, xy=(0, 0))
                text_width = text_bbox[2] - text_bbox[0]
                text_height = text_bbox[3] - text_bbox[1]

            x = (image.width - text_width) // 2
            y = (image.height - text_height) // 2
            draw.text((x, y), phrase, font=font, fill=text_color)
            if random.choice([True, False]):
                image = image.filter(ImageFilter.GaussianBlur(radius=random.uniform(0.5, 1.5)))

            image_filename = f"{phrase}_{font_file.split('.')[0]}.png"
            image_path = os.path.join(output_dir, image_filename)
            image.save(image_path)
        except Exception as e:
            print(f"An error occurred while processing the phrase '{phrase}' with font {font_file}: {e}")
            continue

shutil.make_archive('./generated_images', 'zip', './generated_images')

files.download('./generated_images.zip')

"""### ЗАГРУЗКА ДАТАСЕТА"""

import os
from sklearn.model_selection import train_test_split
import torch
from torch.utils.data import DataLoader
from sklearn.preprocessing import LabelEncoder
from PIL import Image
from torchvision import transforms

image_folder = "generated_images"
image_files = [f for f in os.listdir(image_folder) if f.endswith('.png')]
labels = [" ".join(f.split('_')[1:-1]) for f in image_files]

import cv2
from PIL import Image, ImageOps
from torchvision import transforms
import numpy as np

image_paths = [os.path.join(image_folder, f) for f in image_files]
train_paths, test_paths, y_train, y_test = train_test_split(image_paths, labels, test_size=0.2, random_state=42)

def parse_function(filename):
    image = cv2.imdecode(np.fromfile(filename, dtype=np.uint8), cv2.IMREAD_GRAYSCALE)

    _, image = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)

    if cv2.countNonZero(image) > (image.shape[0] * image.shape[1] // 2):
        image = cv2.bitwise_not(image)

    image = Image.fromarray(image, 'L')

    transform = transforms.Compose([
        transforms.Resize((100, 300)),
        transforms.ToTensor()
    ])

    return transform(image)


train_images = torch.stack([parse_function(f) for f in train_paths])
train_labels = [str(label) for label in y_train]
test_images = torch.stack([parse_function(f) for f in test_paths])
test_labels = [str(label) for label in y_test]

label_to_images = {}
for image, label in zip(train_images, train_labels):
    if label not in label_to_images:
        label_to_images[label] = []
    label_to_images[label].append(image)

import random

class TripletDataset(torch.utils.data.Dataset):
    def __init__(self, label_to_images):
        self.label_to_images = label_to_images
        self.triplet_indices = []

        for label, images in self.label_to_images.items():
            other_labels = [k for k in label_to_images.keys() if k != label]
            for anchor_idx, anchor_img in enumerate(images):
                for _ in range(1):
                    positive_idx = random.choice(range(len(images)))
                    negative_label = random.choice(other_labels)
                    negative_idx = random.choice(range(len(self.label_to_images[negative_label])))

                    self.triplet_indices.append((label, anchor_idx, positive_idx, negative_label, negative_idx))

    def __len__(self):
        return len(self.triplet_indices)

    def __getitem__(self, idx):
        label, anchor_idx, positive_idx, negative_label, negative_idx = self.triplet_indices[idx]
        anchor_img = self.label_to_images[label][anchor_idx]
        positive_img = self.label_to_images[label][positive_idx]
        negative_img = self.label_to_images[negative_label][negative_idx]

        return anchor_img, positive_img, negative_img

triplet_dataset = TripletDataset(label_to_images)
triplet_loader = DataLoader(triplet_dataset, batch_size=32, shuffle=True)

"""### СОЗДАНИЕ НЕЙРОНКИ"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchsummary import summary


class BaseNet(nn.Module):
    def __init__(self):
        super(BaseNet, self).__init__()
        self.features = nn.Sequential(
            nn.Conv2d(1, 32, 3), nn.ReLU(),
            nn.Conv2d(32, 32, 3), nn.ReLU(),
            nn.MaxPool2d(2, 2),
            nn.Conv2d(32, 64, 3), nn.ReLU(),
            nn.Conv2d(64, 64, 3), nn.ReLU(),
            nn.MaxPool2d(2, 2),
            nn.Conv2d(64, 128, 3), nn.ReLU(),
            nn.Conv2d(128, 128, 3), nn.ReLU(),
            nn.MaxPool2d(2, 2)
        )
        self.classifier = nn.Sequential(
            nn.AdaptiveAvgPool2d((2, 2)),
            nn.Flatten(),
            nn.Linear(512, 1024), nn.ReLU(),
            nn.Linear(1024, 512), nn.ReLU(),
            nn.Linear(512, 256)
        )

    def forward(self, x):
        x = self.features(x)
        x = self.classifier(x)
        return x

class TripletLoss(nn.Module):
    def __init__(self, margin=0.2):
        super(TripletLoss, self).__init__()
        self.margin = margin

    def forward(self, anchor, positive, negative):
        pos_dist = torch.sum((anchor - positive)**2, dim=1)
        neg_dist = torch.sum((anchor - negative)**2, dim=1)
        loss = torch.clamp(pos_dist - neg_dist + self.margin, min=0.0)
        return torch.mean(loss)

model = BaseNet()
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)
summary(model, input_size=(1, 100, 300))

"""### ОБУЧЕНИЕ НЕЙРОНКИ"""

from collections import defaultdict
import numpy as np

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

base_net = BaseNet().to(device)
triplet_loss = TripletLoss(margin=1)

# optimizer = optim.Adam(base_net.parameters(), lr=0.001)
optimizer = optim.RMSprop(base_net.parameters(), lr=0.001)

def euclidean_distance(a, b):
    return torch.norm(a - b, p=2)

def predict_font(embedding, average_embeddings):
    min_distance = float('inf')
    best_label = None

    embedding = torch.tensor(embedding) if type(embedding) is not torch.Tensor else embedding

    for label, avg_emb in average_embeddings.items():
        avg_emb = torch.tensor(avg_emb) if type(avg_emb) is not torch.Tensor else avg_emb
        distance = euclidean_distance(embedding, avg_emb)

        if distance.item() < min_distance:
            min_distance = distance.item()
            best_label = label

    return best_label

def predict_top_fonts(embedding, average_embeddings, top_n=3):
    distances = []

    embedding = torch.tensor(embedding) if type(embedding) is not torch.Tensor else embedding

    for label, avg_emb in average_embeddings.items():
        avg_emb = torch.tensor(avg_emb) if type(avg_emb) is not torch.Tensor else avg_emb
        distance = euclidean_distance(embedding, avg_emb)
        distances.append((label, distance.item()))

    distances.sort(key=lambda x: x[1])

    top_labels = [label for label, _ in distances[:top_n]]

    return top_labels

batch_size = 32
from tqdm import tqdm

def get_average_embeddings(images, labels, batch_size):
    test_embeddings = []
    for i in range(0, len(images), batch_size):
        test_batch = images[i:i+batch_size].to(device)

        batch_test_embeddings = base_net(test_batch).detach().cpu().numpy()
        test_embeddings.extend(batch_test_embeddings)

    label_to_embeddings = defaultdict(list)
    for emb, label in zip(test_embeddings, labels):
        label_to_embeddings[label].append(emb)

    average_embeddings = {label: np.mean(embs, axis=0) for label, embs in label_to_embeddings.items()}
    return average_embeddings, test_embeddings


average_embeddings = None
test_average_embeddings = {}
train_average_embeddings = {}

for epoch in range(12):
    triplet_dataset = TripletDataset(label_to_images)
    triplet_loader = DataLoader(triplet_dataset, batch_size=32, shuffle=True)
    pbar = tqdm(triplet_loader, desc=f"Epoch {epoch+1}")
    total_loss = 0.0
    batch_count = 0
    for batch in pbar:
        optimizer.zero_grad()

        anchors, positives, negatives = batch
        anchors, positives, negatives = anchors.to(device), positives.to(device), negatives.to(device)

        anchor_embedding = base_net(anchors)
        positive_embedding = base_net(positives)
        negative_embedding = base_net(negatives)

        loss = triplet_loss(anchor_embedding, positive_embedding, negative_embedding)

        loss.backward()
        optimizer.step()

        total_loss += loss.item()
        batch_count += 1
        average_loss = total_loss / batch_count

        pbar.set_postfix({"Batch Loss": loss.item(), "Average Loss": average_loss})

    # Оценка точности модели после каждой эпохи
    correct_predictions_top_1 = 0
    correct_predictions_top_5 = 0
    epoch_test_average_embeddings, test_embeddings = get_average_embeddings(test_images, test_labels, batch_size)
    epoch_train_average_embeddings, train_test_embeddings = get_average_embeddings(train_images, train_labels, batch_size)

    # Получение средних эмбеддингов для тестового набора
    test_average_embeddings[epoch] = epoch_test_average_embeddings

    # Получение средних эмбеддингов для обучающего набора
    train_average_embeddings[epoch] = epoch_train_average_embeddings

    # Расчет точности модели
    for emb_tensor, true_label in zip(test_embeddings, test_labels):
        predicted_labels = predict_top_fonts(emb_tensor, epoch_train_average_embeddings, 5)
        if predicted_labels[0] == true_label:
            correct_predictions_top_1 += 1
        if true_label in predicted_labels:
            correct_predictions_top_5 += 1

    accuracy1 = (correct_predictions_top_1 / len(test_images)) * 100
    accuracy5 = (correct_predictions_top_5 / len(test_images)) * 100

    print(f"Accuracy top1/top5 after epoch {epoch+1}: {accuracy1} / {accuracy5}%")

"""### СОХРАНЕНИЕ ВЕСОВ И ЭМБЕДДИНГОВ НА ДИСК"""

torch.save(base_net.state_dict(), 'model.pth')

files.download('./model.pth')

import pickle
with open('test_average_embeddings.pkl', 'wb') as f:
    pickle.dump(test_average_embeddings[11], f)

files.download('./test_average_embeddings.pkl')